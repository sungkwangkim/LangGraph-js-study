"""
Persisted ChromaDB ê²€ìƒ‰ ë„êµ¬ (HuggingFace/Qwen ì„ë² ë”© ì»¬ë ‰ì…˜).

ì˜ˆì‹œ:
    python store/test._qwen.py --query "ë¹„ ì˜¤ëŠ” ë‚  ë¨¹ê¸° ì¢‹ì€ ìŒì‹" --k 5
"""

import argparse
import os
from typing import List, Tuple

from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

load_dotenv()

CHROMA_DB_PATH = "./chroma_db_qwen"
COLLECTION_NAME = "jamsil_restaurants_qwen"
HUGGINGFACE_MODEL = os.getenv("HUGGINGFACE_MODEL", "BAAI/bge-m3")
HUGGINGFACE_DEVICE = os.getenv("HUGGINGFACE_DEVICE", "cpu")
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN")


def load_vectorstore() -> Chroma:
    """Persisted Chroma ì»¬ë ‰ì…˜ ë¡œë“œ (HuggingFace ì„ë² ë”©)."""
    embeddings = HuggingFaceEmbeddings(
        model_name=HUGGINGFACE_MODEL,
        model_kwargs={
            "device": HUGGINGFACE_DEVICE,
            "trust_remote_code": True,
            "token": HUGGINGFACE_TOKEN,
        },
        encode_kwargs={
            "normalize_embeddings": True,
            "batch_size": 8,
        },
    )

    return Chroma(
        collection_name=COLLECTION_NAME,
        embedding_function=embeddings,
        persist_directory=CHROMA_DB_PATH,
    )


def search(vectorstore: Chroma, query: str, k: int) -> List[Tuple[float, dict, str]]:
    """ì¿¼ë¦¬ë¥¼ ê²€ìƒ‰í•˜ê³  (ì ìˆ˜, ë©”íƒ€ë°ì´í„°, ë‚´ìš© ìš”ì•½) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜."""
    results = vectorstore.similarity_search_with_relevance_scores(query, k=k)
    formatted = []
    for doc, score in results:  # (Document, score)
        content = doc.page_content or ""
        summary = f"{content[:240]}..." if len(content) > 240 else content
        formatted.append((score, doc.metadata, summary))
    return formatted


def main() -> None:
    parser = argparse.ArgumentParser(description="ChromaDB (Qwen/HF) ì§ˆì˜")
    parser.add_argument("--query", "-q", required=True, help="ê²€ìƒ‰í•  ì¿¼ë¦¬")
    parser.add_argument("--k", "-k", type=int, default=3, help="ê°€ì ¸ì˜¬ ê²°ê³¼ ê°œìˆ˜ (default: 3)")
    args = parser.parse_args()

    if not os.path.exists(CHROMA_DB_PATH):
        raise FileNotFoundError(f"ChromaDB ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {CHROMA_DB_PATH} (ë¨¼ì € embedding_qwen.py ì‹¤í–‰)")

    print(f"ğŸ“¦ ChromaDB ë¶ˆëŸ¬ì˜¤ê¸°: {CHROMA_DB_PATH} (collection: {COLLECTION_NAME})")
    print(f"   ëª¨ë¸: {HUGGINGFACE_MODEL} | ë””ë°”ì´ìŠ¤: {HUGGINGFACE_DEVICE}")
    vectorstore = load_vectorstore()

    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {args.query} (k={args.k})\n")
    results = search(vectorstore, args.query, args.k)

    if not results:
        print("âš ï¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for idx, (score, metadata, snippet) in enumerate(results, start=1):
        print(f"--- ê²°ê³¼ {idx} ---")
        print(f"score: {score:.4f}")
        print(f"name: {metadata.get('name')}")
        print(f"category: {metadata.get('category')}")
        print(f"signature_menu: {metadata.get('signature_menu')}")
        print(f"location_type: {metadata.get('location_type')}")
        print(f"naver_review_count: {metadata.get('naver_review_count')}")
        print(f"weather_tags: {metadata.get('weather_tags')}")
        print("content:", snippet)
        print()


if __name__ == "__main__":
    main()
